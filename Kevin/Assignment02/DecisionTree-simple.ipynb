{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "from math import log\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea is not to deal with index but rather the heading of the columns. Therefore we use pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col, n_class):\n",
    "    \"\"\"\n",
    "    This function calculates the entropy of the dataset\n",
    "    \n",
    "    @param target_col: The column where the target values are stored\n",
    "    @param n_class: For log base\n",
    "    \n",
    "    return: entropy of the target values w.r.t the dataset\n",
    "    \"\"\"\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*log((counts[i]/np.sum(counts)),n_class) for i in range(len(elements))])\n",
    "    return entropy\n",
    "    \n",
    "def InfoGain(data,split_attribute_name, n_class, target_name=\"Play Tennis\"):\n",
    "    \"\"\"\n",
    "    This function computes the information gain of a feature by substracting total entropy with weighted\n",
    "    entropy of the values in the feature respectively\n",
    "    \n",
    "    @param data: input data set \n",
    "    @param split_attribute_name: feature column\n",
    "    @param n_class: for log base\n",
    "    @target_name: name of target column\n",
    "    \n",
    "    return: information gain\n",
    "    \"\"\"    \n",
    "    #Compute the entropy of the original dataset\n",
    "    total_entropy = entropy(data[target_name], n_class)\n",
    "\n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name], n_class) for i in range(len(vals))])\n",
    "    \n",
    "    #Calculate the information gain by substrating weighted entropy from total entropy\n",
    "    return total_entropy - Weighted_Entropy\n",
    "\n",
    "def ID3_xml(data,originaldata,features,n_class,target_attribute_name=\"Play Tennis\",best_feature = None,\n",
    "            value = None, parent_node_class = None, space = ''):\n",
    "    \"\"\"\n",
    "    This function compute the ID3 algorithm of a decision tree\n",
    "    \n",
    "    @param data: Data that the algorithm is currently running\n",
    "    @param original_data: Orignial dataset that includes all the feature columns\n",
    "    @param features: A list containing feature column names\n",
    "    @param n_class: Number of class as log base\n",
    "    @param target_attribute_name: Column name where the target values are stored.\n",
    "    @param best_feature: Best feature used at the particular iteration\n",
    "    @param value: The value of the best feature used at the particular iteration\n",
    "    @param parent_node_class: The best target feature value will be stored\n",
    "    \n",
    "    reference: https://www.python-course.eu/Decision_Trees.php\n",
    "    \"\"\"   \n",
    "    #Stopping criteria for creating a leaf node\n",
    "    #If all target_values have the same value, return this value, because entropy will be 0\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        space+= ' '\n",
    "        ent = entropy(data[target_attribute_name], n_class)\n",
    "        target_val = np.unique(data[target_attribute_name])[0]\n",
    "        print(space+'entropy=\"{}\"feature=\"{}\"value\"{}\"class\"{}\"'.format(ent,best_feature, value, target_val))\n",
    "        return target_val\n",
    "    \n",
    "    #Return the mode target feature value in the original dataset if the dataset is empty\n",
    "    elif len(data)==0:\n",
    "        #axis 1 is the list where the counts are stored\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #Grow tree\n",
    "    else:\n",
    "        print()\n",
    "        if (value==None): pass\n",
    "        else:\n",
    "            ent = entropy(data[target_attribute_name], n_class)\n",
    "            print('entropy=\"{}\"feature=\"{}\"value\"{}\"'.format(ent,best_feature, value))\n",
    "        #Set the default value for parent node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        #Compute the gain of each feature respectively \n",
    "        item_values = [InfoGain(data,feature, n_class, target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        #retrieving the index of the highest gain feature for best feature\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #The root gets the name of the feature (best_feature) with the maximum info gain\n",
    "        tree = {best_feature:{}}\n",
    "        #Remove(isolate) the feature with the best inforamtion gain from the feature space\n",
    "        #because we are sorting values w.r.t the best feature\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Recursively compute the ID3 algorithm for each of those sub_datasets with the new parameters\n",
    "            subtree = ID3_xml(sub_data,data,features,n_class,target_attribute_name, \n",
    "                              best_feature, value, parent_node_class, space)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            #nesting dictionary\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 5\n"
     ]
    }
   ],
   "source": [
    "input_path = 'simple.csv'\n",
    "input_ds = pd.read_csv(input_path)\n",
    "n_cols = len(input_ds.columns)\n",
    "print(\"Number of columns:\", n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook Temperature Humidity  Windy  Play Tennis\n",
      "0     Sunny         Hot     High    Weak         No \n",
      "1     Sunny         Hot     High  Strong         No \n",
      "2  Overcast         Hot     High    Weak         Yes\n",
      "3     Rainy        Mild     High    Weak         Yes\n",
      "4     Rainy        Cool   Normal    Weak         Yes\n"
     ]
    }
   ],
   "source": [
    "print (input_ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in Outlook is: ['Overcast' 'Rainy' 'Sunny']\n",
      "Values in Temperature is: ['Cool' 'Hot' 'Mild']\n",
      "Values in Humidity is: ['High' 'Normal']\n",
      "Values in Windy  is: ['Strong' 'Weak']\n",
      "Values in Play Tennis is: ['No ' 'Yes']\n",
      "Number of classes:  2\n"
     ]
    }
   ],
   "source": [
    "for headings in input_ds:\n",
    "    print(\"Values in {} is: {}\".format(headings, np.unique(input_ds[headings])))\n",
    "    \n",
    "n_class = len(set(input_ds['Play Tennis']))\n",
    "print(\"Number of classes: \", n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: \"0.9402859586706309\"\n",
      "\n",
      " entropy=\"0.0\"feature=\"Outlook\"value\"Overcast\"class\"Yes\"\n",
      "\n",
      "entropy=\"0.9709505944546686\"feature=\"Outlook\"value\"Rainy\"\n",
      " entropy=\"0.0\"feature=\"Windy \"value\"Strong\"class\"No \"\n",
      " entropy=\"0.0\"feature=\"Windy \"value\"Weak\"class\"Yes\"\n",
      "\n",
      "entropy=\"0.9709505944546686\"feature=\"Outlook\"value\"Sunny\"\n",
      " entropy=\"0.0\"feature=\"Humidity\"value\"High\"class\"No \"\n",
      " entropy=\"0.0\"feature=\"Humidity\"value\"Normal\"class\"Yes\"\n"
     ]
    }
   ],
   "source": [
    "init_ent = entropy(input_ds['Play Tennis'], n_class)\n",
    "print('Entropy: \"{}\"'.format(init_ent))\n",
    "tree = ID3_xml(input_ds, input_ds, input_ds.columns[:-1], n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overcast\n",
      "Rainy\n",
      "Sunny\n"
     ]
    }
   ],
   "source": [
    "for value in np.unique(input_ds['Outlook']):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': {'Overcast': 'Yes', 'Rainy': {'Windy ': {'Strong': 'No ', 'Weak': 'Yes'}}, 'Sunny': {'Humidity': {'High': 'No ', 'Normal': 'Yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
