{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import time\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea is not to deal with index but rather the heading of the columns. Therefore we use pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col, n_class):\n",
    "    '''\n",
    "    Compute Entropy\n",
    "    @param target_col: the columns of the target value\n",
    "    @param n_class: the number of class as log base\n",
    "    \n",
    "    return: entropy \n",
    "    '''\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    ent = 0\n",
    "    for i in range(len(elements)):\n",
    "        ent += (-counts[i]/np.sum(counts))*log(counts[i]/np.sum(counts), n_class)\n",
    "    return ent    \n",
    "\n",
    "def gain(data, att_name, n_class, target_col_name = 'class'):\n",
    "    \n",
    "    assert type(att_name)==str, \"Expected type str for att_name!\"\n",
    "    \n",
    "    total_entropy = entropy(data[target_col_name], n_class)\n",
    "    #return non-duplicate values from the column and it's frequency\n",
    "    vals,counts= np.unique(data[att_name],return_counts=True)\n",
    "    w_entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "        #filter out the class with its corresponding attributes w.r.t features\n",
    "        att = data.where(data[att_name]==vals[i]).dropna()[target_col_name]\n",
    "        w_entropy += (counts[i]/np.sum(counts))*entropy(att, n_class)\n",
    "    return total_entropy- w_entropy\n",
    "\n",
    "def gain02(data, att_name, n_class, total_entropy, target_col_name = 'class'):\n",
    "    \n",
    "    assert type(att_name)==str, \"Expected type str for att_name!\"\n",
    "    \n",
    "    #return non-duplicate values from the column and it's frequency\n",
    "    vals,counts= np.unique(data[att_name],return_counts=True)\n",
    "    w_entropy = 0\n",
    "    for i in range(len(vals)):\n",
    "        #filter out the class with its corresponding attributes w.r.t features\n",
    "        att = data.where(data[att_name]==vals[i]).dropna()[target_col_name]\n",
    "        w_entropy += (counts[i]/np.sum(counts))*entropy(att, n_class)\n",
    "    return total_entropy- w_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "input_path = 'car.csv'\n",
    "input_ds = pd.read_csv(input_path, header = None)\n",
    "n_cols = len(input_ds.columns)\n",
    "print(\"Number of columns:\", n_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['att0', 'att1', 'att2', 'att3', 'att4', 'att5', 'class']\n"
     ]
    }
   ],
   "source": [
    "#initiate empty list for column name\n",
    "col_name = []\n",
    "\n",
    "for i in range(n_cols):\n",
    "    #last column is the target value\n",
    "    if (i == n_cols-1):\n",
    "        col_name.append('class')\n",
    "    else:\n",
    "        col_name.append('att{}'.format(i))\n",
    "        \n",
    "print(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    att0   att1 att2 att3   att4  att5  class\n",
      "0  vhigh  vhigh    2    2  small   low  unacc\n",
      "1  vhigh  vhigh    2    2  small   med  unacc\n",
      "2  vhigh  vhigh    2    2  small  high  unacc\n",
      "3  vhigh  vhigh    2    2    med   low  unacc\n",
      "4  vhigh  vhigh    2    2    med   med  unacc\n"
     ]
    }
   ],
   "source": [
    "#assigning column names to data set\n",
    "input_ds.columns = col_name\n",
    "print (input_ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes in att0 is: {'vhigh', 'med', 'low', 'high'}\n",
      "Attributes in att1 is: {'vhigh', 'med', 'low', 'high'}\n",
      "Attributes in att2 is: {'2', '5more', '4', '3'}\n",
      "Attributes in att3 is: {'2', '4', 'more'}\n",
      "Attributes in att4 is: {'med', 'small', 'big'}\n",
      "Attributes in att5 is: {'low', 'med', 'high'}\n",
      "Attributes in class is: {'vgood', 'acc', 'good', 'unacc'}\n",
      "Number of classes:  4\n"
     ]
    }
   ],
   "source": [
    "for headings in input_ds:\n",
    "    print(\"Attributes in {} is: {}\".format(headings, set(input_ds[headings])))\n",
    "    \n",
    "n_class = len(set(input_ds['class']))\n",
    "print(\"Number of classes: \", n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation for few steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6028704850060875\n"
     ]
    }
   ],
   "source": [
    "#sanity check for entropy for first step \n",
    "total_entropy = entropy(input_ds['class'], n_class)\n",
    "print(total_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['att0', 'att1', 'att2', 'att3', 'att4', 'att5']\n"
     ]
    }
   ],
   "source": [
    "features = col_name[:n_cols-1] #ommit the class feature\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att5\n"
     ]
    }
   ],
   "source": [
    "#loop through the feature columns to calculate gain\n",
    "info_gain = [gain(input_ds, feature, n_class) for feature in features]\n",
    "highest_gain_index = np.argmax(info_gain)\n",
    "best_feature = features[highest_gain_index]\n",
    "\n",
    "print(best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['att0', 'att1', 'att2', 'att3', 'att4']\n"
     ]
    }
   ],
   "source": [
    "#remove the best column of the best feature\n",
    "features = [i for i in features if i!=best_feature]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy = 0.8077559247898061, feature = att5, value = high\n",
      "entropy = 0.0, feature = att5, value = low, class = unacc\n",
      "entropy = 0.607578995397061, feature = att5, value = med\n"
     ]
    }
   ],
   "source": [
    "#split the data by matching the value with respect to non-duplicate values\n",
    "# in the feature column\n",
    "sub_data_list = []\n",
    "best_feature_col = input_ds[best_feature]\n",
    "for value in np.unique(best_feature_col):\n",
    "    sub_data = input_ds.where(best_feature_col==value).dropna()\n",
    "#     print(sub_data)  \n",
    "    if len(np.unique(sub_data['class']))<=1:\n",
    "        ent = entropy(sub_data['class'], n_class)\n",
    "        target = np.unique(sub_data['class'])[0]\n",
    "        print(\"entropy = {}, feature = {}, value = {}, class = {}\".format(ent, best_feature, value, target))\n",
    "        #become tree\n",
    "    else:\n",
    "        ent = entropy(sub_data['class'], n_class)\n",
    "        print(\"entropy = {}, feature = {}, value = {}\".format(ent, best_feature, value))\n",
    "        sub_data_list.append(sub_data)\n",
    "        #grow tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att0</th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att0   att1   att2  att3   att4 att5  class\n",
       "1     vhigh  vhigh      2     2  small  med  unacc\n",
       "4     vhigh  vhigh      2     2    med  med  unacc\n",
       "7     vhigh  vhigh      2     2    big  med  unacc\n",
       "10    vhigh  vhigh      2     4  small  med  unacc\n",
       "13    vhigh  vhigh      2     4    med  med  unacc\n",
       "16    vhigh  vhigh      2     4    big  med  unacc\n",
       "19    vhigh  vhigh      2  more  small  med  unacc\n",
       "22    vhigh  vhigh      2  more    med  med  unacc\n",
       "25    vhigh  vhigh      2  more    big  med  unacc\n",
       "28    vhigh  vhigh      3     2  small  med  unacc\n",
       "31    vhigh  vhigh      3     2    med  med  unacc\n",
       "34    vhigh  vhigh      3     2    big  med  unacc\n",
       "37    vhigh  vhigh      3     4  small  med  unacc\n",
       "40    vhigh  vhigh      3     4    med  med  unacc\n",
       "43    vhigh  vhigh      3     4    big  med  unacc\n",
       "46    vhigh  vhigh      3  more  small  med  unacc\n",
       "49    vhigh  vhigh      3  more    med  med  unacc\n",
       "52    vhigh  vhigh      3  more    big  med  unacc\n",
       "55    vhigh  vhigh      4     2  small  med  unacc\n",
       "58    vhigh  vhigh      4     2    med  med  unacc\n",
       "61    vhigh  vhigh      4     2    big  med  unacc\n",
       "64    vhigh  vhigh      4     4  small  med  unacc\n",
       "67    vhigh  vhigh      4     4    med  med  unacc\n",
       "70    vhigh  vhigh      4     4    big  med  unacc\n",
       "73    vhigh  vhigh      4  more  small  med  unacc\n",
       "76    vhigh  vhigh      4  more    med  med  unacc\n",
       "79    vhigh  vhigh      4  more    big  med  unacc\n",
       "82    vhigh  vhigh  5more     2  small  med  unacc\n",
       "85    vhigh  vhigh  5more     2    med  med  unacc\n",
       "88    vhigh  vhigh  5more     2    big  med  unacc\n",
       "...     ...    ...    ...   ...    ...  ...    ...\n",
       "1639    low    low      2  more  small  med  unacc\n",
       "1642    low    low      2  more    med  med    acc\n",
       "1645    low    low      2  more    big  med   good\n",
       "1648    low    low      3     2  small  med  unacc\n",
       "1651    low    low      3     2    med  med  unacc\n",
       "1654    low    low      3     2    big  med  unacc\n",
       "1657    low    low      3     4  small  med    acc\n",
       "1660    low    low      3     4    med  med    acc\n",
       "1663    low    low      3     4    big  med   good\n",
       "1666    low    low      3  more  small  med    acc\n",
       "1669    low    low      3  more    med  med   good\n",
       "1672    low    low      3  more    big  med   good\n",
       "1675    low    low      4     2  small  med  unacc\n",
       "1678    low    low      4     2    med  med  unacc\n",
       "1681    low    low      4     2    big  med  unacc\n",
       "1684    low    low      4     4  small  med    acc\n",
       "1687    low    low      4     4    med  med   good\n",
       "1690    low    low      4     4    big  med   good\n",
       "1693    low    low      4  more  small  med    acc\n",
       "1696    low    low      4  more    med  med   good\n",
       "1699    low    low      4  more    big  med   good\n",
       "1702    low    low  5more     2  small  med  unacc\n",
       "1705    low    low  5more     2    med  med  unacc\n",
       "1708    low    low  5more     2    big  med  unacc\n",
       "1711    low    low  5more     4  small  med    acc\n",
       "1714    low    low  5more     4    med  med   good\n",
       "1717    low    low  5more     4    big  med   good\n",
       "1720    low    low  5more  more  small  med    acc\n",
       "1723    low    low  5more  more    med  med   good\n",
       "1726    low    low  5more  more    big  med   good\n",
       "\n",
       "[576 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att3\n"
     ]
    }
   ],
   "source": [
    "#loop through the feature columns to calculate gain\n",
    "info_gain = [gain(sub_data_list[1], feature, n_class) for feature in features]\n",
    "highest_gain_index = np.argmax(info_gain)\n",
    "best_feature = features[highest_gain_index]\n",
    "\n",
    "print(best_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy = 0.0, feature = att3, value = 2, class = unacc\n",
      "entropy = 0.7403599651474037, feature = att3, value = 4\n",
      "entropy = 0.738757044860997, feature = att3, value = more\n"
     ]
    }
   ],
   "source": [
    "#split the data by matching the value with respect to non-duplicate values\n",
    "# in the feature column\n",
    "sub_data_list = []\n",
    "best_feature_col = input_ds[best_feature]\n",
    "for value in np.unique(best_feature_col):\n",
    "    sub_data = input_ds.where(best_feature_col==value).dropna()\n",
    "#     print(sub_data)  \n",
    "    if len(np.unique(sub_data['class']))<=1:\n",
    "        ent = entropy(sub_data['class'], n_class)\n",
    "        target = np.unique(sub_data['class'])[0]\n",
    "        print(\"entropy = {}, feature = {}, value = {}, class = {}\".format(ent, best_feature, value, target))\n",
    "        #become tree\n",
    "    else:\n",
    "        ent = entropy(sub_data['class'], n_class)\n",
    "        print(\"entropy = {}, feature = {}, value = {}\".format(ent, best_feature, value))\n",
    "        sub_data_list.append(sub_data)\n",
    "        #grow tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_id3(original_data, data, features, n_class, target_col_name = 'class', parent_node_class = None):\n",
    "    '''\n",
    "    This function is a recursive function for calculating decision tree with ID3 algorithm.\n",
    "    \n",
    "    @param original_data: Orignial dataset that includes all the feature columns\n",
    "    @param data: Data that the algorithm is currently running\n",
    "    @param features: A list containing feature column names\n",
    "    @param n_class: Number of class as log base\n",
    "    @param target_col_name: Column name where the target values are stored.\n",
    "    @param parent_node_class: The best target feature value will be stored\n",
    "    \n",
    "    return: tree\n",
    "    '''\n",
    "    #specify stopping criteria\n",
    "    \n",
    "    #if the values in the class column is the same, return the value\n",
    "    if len(np.unique(data[target_col_name]))<=1:\n",
    "        return np.unique(data[target_col_name])[0]\n",
    "    #if dataset is empty, output the value in the target column with the \n",
    "    # highest occurence \n",
    "    elif len(data)==0:\n",
    "        #axis 1 is the list where the counts are stored\n",
    "        highest_count_index = np.argmax(np.unique(original_data[target_col_name],return_counts=True)[1])\n",
    "        return np.unique(original_data[target_col_name])[highest_count_index]\n",
    "    #if feature space is empty, output parent_node_class\n",
    "    elif len(features)==0:\n",
    "        return parent_node_class\n",
    "    #compute decision tree\n",
    "    else: \n",
    "        #set the mode of the target feature value of the current node as the default node\n",
    "        highest_count_index = np.argmax(np.unique(data[target_col_name],return_counts=True)[1])\n",
    "        parent_node_class = np.unique(data[target_col_name])[highest_count_index]\n",
    "        \n",
    "        #loop across the feature columns for highest gain\n",
    "        info_gain = [gain(data, feature, n_class) for feature in features]\n",
    "        #retrieve the index of the highest gain so that we can know the feature\n",
    "        highest_gain_index = np.argmax(info_gain)\n",
    "        best_feature = features[highest_gain_index]\n",
    "        \n",
    "        #Assign name to the root or parent nodes\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        #remove the best feature from the previous step\n",
    "        features = [i for i in features if i!= best_feature]\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature]==value).dropna()\n",
    "            \n",
    "            #recursive starts here\n",
    "            sub_tree = decision_tree_id3(data, sub_data, features, n_class, parent_node_class)\n",
    "            #add sub tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= input_ds\n",
    "target_col_name ='class'\n",
    "if len(np.unique(data[target_col_name]))<=1:\n",
    "    np.unique(data[target_col_name])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'unacc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unacc'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-56229f946b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree_id3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-72d6f2a79804>\u001b[0m in \u001b[0;36mdecision_tree_id3\u001b[0;34m(original_data, data, features, n_class, target_col_name, parent_node_class)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m#recursive starts here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0msub_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree_id3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_node_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;31m#add sub tree under the root node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-72d6f2a79804>\u001b[0m in \u001b[0;36mdecision_tree_id3\u001b[0;34m(original_data, data, features, n_class, target_col_name, parent_node_class)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#if the values in the class column is the same, return the value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#if dataset is empty, output the value in the target column with the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'unacc'"
     ]
    }
   ],
   "source": [
    "features = col_name[:n_cols-1]\n",
    "test = decision_tree_id3(input_ds, input_ds, features, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03685197346074287\n",
      "0.002242858313315943\n",
      "0.015004070623802601\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    info_gain = gain(input_ds, feature, n_class)\n",
    "    print(info_gain)\n",
    "highest_gain_index = np.argmax(info_gain)\n",
    "max_gain_feature = features[highest_gain_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'att1': {}}\n"
     ]
    }
   ],
   "source": [
    "tree = {max_gain_feature:{}}\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['acc', 'good', 'unacc', 'vgood'], dtype=object),\n",
       " array([ 384,   69, 1210,   65]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(input_ds['class'],return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a dataset.\n",
    "    The only parameter of this function is the target_col parameter which specifies the target column\n",
    "    \"\"\"\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy\n",
    "################### \n",
    "    \n",
    "###################\n",
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset. This function takes three parameters:\n",
    "    1. data = The dataset for whose feature the IG should be calculated\n",
    "    2. split_attribute_name = the name of the feature for which the information gain should be calculated\n",
    "    3. target_name = the name of the target feature. The default for this example is \"class\"\n",
    "    \"\"\"    \n",
    "    #Calculate the entropy of the total dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    \n",
    "    #Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    #Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain\n",
    "       \n",
    "###################\n",
    "###################\n",
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):\n",
    "    \"\"\"\n",
    "    ID3 Algorithm: This function takes five paramters:\n",
    "    1. data = the data for which the ID3 algorithm should be run --> In the first run this equals the total dataset\n",
    " \n",
    "    2. originaldata = This is the original dataset needed to calculate the mode target feature value of the original dataset\n",
    "    in the case the dataset delivered by the first parameter is empty\n",
    "    3. features = the feature space of the dataset . This is needed for the recursive call since during the tree growing process\n",
    "    we have to remove features from our dataset --> Splitting at each node\n",
    "    4. target_attribute_name = the name of the target attribute\n",
    "    5. parent_node_class = This is the value or class of the mode target feature value of the parent node for a specific node. This is \n",
    "    also needed for the recursive call since if the splitting leads to a situation that there are no more features left in the feature\n",
    "    space, we want to return the mode target feature value of the direct parent node.\n",
    "    \"\"\"   \n",
    "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#\n",
    "    \n",
    "    #If all target_values have the same value, return this value\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    #If the dataset is empty, return the mode target feature value in the original dataset\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    #If the feature space is empty, return the mode target feature value of the direct parent node --> Note that\n",
    "    #the direct parent node is that node which has called the current run of the ID3 algorithm and hence\n",
    "    #the mode target feature value is stored in the parent_node_class variable.\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    #If none of the above holds true, grow the tree!\n",
    "    \n",
    "    else:\n",
    "        #Set the default value for this node --> The mode target feature value of the current node\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        \n",
    "        #Select the feature which best splits the dataset\n",
    "        item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information\n",
    "        #gain in the first run\n",
    "        tree = {best_feature:{}}\n",
    "        \n",
    "        \n",
    "        #Remove the feature with the best inforamtion gain from the feature space\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        #Grow a branch under the root node for each possible value of the root node feature\n",
    "        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            \n",
    "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!\n",
    "            subtree = ID3(sub_data,data,features,target_attribute_name,parent_node_class)\n",
    "            \n",
    "            #Add the sub tree, grown from the sub_dataset to the tree under the root node\n",
    "            tree[best_feature][value] = subtree\n",
    "            \n",
    "        return(tree) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ID3(input_ds, input_ds, input_ds.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'att5': {'high': {'att3': {'2': 'unacc', '4': {'att0': {'high': {'att1': {'high': 'acc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}, 'low': {'att1': {'high': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'acc', '3': 'acc', '4': 'vgood', '5more': 'vgood'}}, 'small': 'acc'}}, 'low': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'good', '4': 'vgood', '5more': 'vgood'}}, 'small': 'good'}}, 'med': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'good', '4': 'vgood', '5more': 'vgood'}}, 'small': 'good'}}, 'vhigh': 'acc'}}, 'med': {'att1': {'high': 'acc', 'low': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'good', '4': 'vgood', '5more': 'vgood'}}, 'small': 'good'}}, 'med': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'acc', '3': 'acc', '4': 'vgood', '5more': 'vgood'}}, 'small': 'acc'}}, 'vhigh': 'acc'}}, 'vhigh': {'att1': {'high': 'unacc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}}}, 'more': {'att0': {'high': {'att1': {'high': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'low': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'med': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'vhigh': 'unacc'}}, 'low': {'att1': {'high': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'acc', '3': 'vgood', '4': 'vgood', '5more': 'vgood'}}, 'small': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'low': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'vgood', '4': 'vgood', '5more': 'vgood'}}, 'small': {'att2': {'2': 'unacc', '3': 'good', '4': 'good', '5more': 'good'}}}}, 'med': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'vgood', '4': 'vgood', '5more': 'vgood'}}, 'small': {'att2': {'2': 'unacc', '3': 'good', '4': 'good', '5more': 'good'}}}}, 'vhigh': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'med': {'att1': {'high': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'low': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'good', '3': 'vgood', '4': 'vgood', '5more': 'vgood'}}, 'small': {'att2': {'2': 'unacc', '3': 'good', '4': 'good', '5more': 'good'}}}}, 'med': {'att4': {'big': 'vgood', 'med': {'att2': {'2': 'acc', '3': 'vgood', '4': 'vgood', '5more': 'vgood'}}, 'small': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'vhigh': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'vhigh': {'att1': {'high': 'unacc', 'low': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'med': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'vhigh': 'unacc'}}}}}}, 'low': 'unacc', 'med': {'att3': {'2': 'unacc', '4': {'att0': {'high': {'att4': {'big': {'att1': {'high': 'acc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}, 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': {'att1': {'high': 'acc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}, '5more': {'att1': {'high': 'acc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}}}, 'small': 'unacc'}}, 'low': {'att1': {'high': 'acc', 'low': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'acc', '4': 'good', '5more': 'good'}}, 'small': 'acc'}}, 'med': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'acc', '4': 'good', '5more': 'good'}}, 'small': 'acc'}}, 'vhigh': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}}}, 'med': {'att1': {'high': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'low': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'acc', '4': 'good', '5more': 'good'}}, 'small': 'acc'}}, 'med': 'acc', 'vhigh': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}}}, 'vhigh': {'att1': {'high': 'unacc', 'low': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'med': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'unacc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'vhigh': 'unacc'}}}}, 'more': {'att0': {'high': {'att4': {'big': {'att1': {'high': 'acc', 'low': 'acc', 'med': 'acc', 'vhigh': 'unacc'}}, 'med': {'att1': {'high': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'low': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'vhigh': 'unacc'}}, 'small': 'unacc'}}, 'low': {'att1': {'high': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'low': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'good', '4': 'good', '5more': 'good'}}, 'small': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'med': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'good', '4': 'good', '5more': 'good'}}, 'small': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'vhigh': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}}}, 'med': {'att1': {'high': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'low': {'att4': {'big': 'good', 'med': {'att2': {'2': 'acc', '3': 'good', '4': 'good', '5more': 'good'}}, 'small': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}}}, 'med': {'att2': {'2': {'att4': {'big': 'acc', 'med': 'acc', 'small': 'unacc'}}, '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'vhigh': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}}}, 'vhigh': {'att1': {'high': 'unacc', 'low': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'med': {'att4': {'big': 'acc', 'med': {'att2': {'2': 'unacc', '3': 'acc', '4': 'acc', '5more': 'acc'}}, 'small': 'unacc'}}, 'vhigh': 'unacc'}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
